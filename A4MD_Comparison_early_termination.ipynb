{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A4MD: Validation of conformational space - Early termination of trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "Through this notebook we are able to validate that the early termination of our framework A4MD covers the conformational space as the full simulation.\n",
    "This notebook also provides visual representatations that helps to analyze the trimmed trajectories in comparison with the full simulation.\n",
    "\n",
    "We are using the FS peptide system  (Ace-A 5(AAARA) 3A-NME) and its trajectories collected using Summit supercomputer. We use the trajectories of the full simulation and also trajectories with early termination using collective variables (CVs) such as Largest Eigen Value (LEV) and Effective Sample Size (ESS)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two cells prepares the environment for processing and visualizing the trajectories by importing various crucial libraries for the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code allows to reload the code in the notebook without restarting the kernel. Since we are using an external file with functions,\n",
    "# this automatically loads the new modifications of that file into the notebook.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyEmma version:  2.5.12\n",
      "You have successfully prepared your environment.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries needed for the execution of the notebook\n",
    "import pyemma.coordinates as coor\n",
    "import mdtraj as md\n",
    "from pyemma.util.contexts import settings\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import pyemma\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import JPCCCK_utils_2_reviews as jpccck\n",
    "from IPython.display import display\n",
    "import dataframe_image as dfi\n",
    "import glob\n",
    "from download_data import download_xtc_files\n",
    "\n",
    "import pkg_resources\n",
    "print(\"PyEmma version: \", pkg_resources.get_distribution(\"pyemma\").version)\n",
    "\n",
    "# You have have successfully prepared your environment.\n",
    "print(\"You have successfully prepared your environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data\n",
    "Make sure you have the full trajectories. The next cell will download the full trajectories from Dataverse. \n",
    "\n",
    "https://doi.org/10.7910/DVN/ML5607\n",
    "\n",
    "Before running the notebook, also make sure you have generated the trimmed trajectories that you want to use for the comparison. The generation of these trajectories can be done by using [our bash script](./execute.sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have download the data previously\n"
     ]
    }
   ],
   "source": [
    "download_xtc_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters\n",
    "This cell defines some variables we need to load the trajectories, analize them and also, save frames on disk.\n",
    "\n",
    "**NOTE:** Make sure you define the paths to your files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 1  # Stride for loading trajectory\n",
    "selection = (\n",
    "    \"protein\"  # Used for the RMSD comparison. This option can be \"protein\" or \"all\"\n",
    ")\n",
    "input_dirs = [\n",
    "    \"./files/xtc_files/output\",\n",
    "    \"./files/xtc_files/output.checkpoint/\"\n",
    "]  # Path fot the full trajectories of the simulation. Each folder containes 20 trajectories\n",
    "trimmed_trajectory_1 = \"./results/trajectories/<Add_your_1_early_terminated_trajectory>.xtc\"  # Path for the trimmed trajectories of the simulation \n",
    "trimmed_trajectory_2 = \"./results/trajectories/<Add_your_2_early_terminated_trajectory>.xtc\"  # Path for the trimmed trajectories of the simulation \n",
    "\n",
    "top_file = \"./files/xtc_files/boxed.pdb\"  # Topology file for the trajectories\n",
    "nstates = 6  # Number of states for the MSM model and the PCCA+\n",
    "SAVE_FRAMES = True  # If True, the frames will be saved in the folder frames_closest\n",
    "SAVE_PLOTS = True # If True, the plots will be saved in the folder plots\n",
    "frames_closest_folder = \"./files/frames/\"  # Folder where the frames will be saved\n",
    "dist_cmap = \"nipy_spectral\"  # Color map for the energy plots\n",
    "size = 20  # Size of the point in the plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this notebook you can generate the comparison of the Full trajectory with other two early-terminated trajectories.\n",
    "\n",
    "Use the cell below to define the titles you want to have for every plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots LEV name:  ESS_-_18%_ESS_-_44%\n"
     ]
    }
   ],
   "source": [
    "#titles\n",
    "full_title = \"Full\" # Define\n",
    "trimmed_1_title = \"ESS - 18%\" # Define\n",
    "trimmed_2_title = \"ESS - 44%\" # Define\n",
    "\n",
    "plots_1_name = trimmed_1_title.replace(\" \",\"_\")\n",
    "plots_2_name = trimmed_2_title.replace(\" \",\"_\")\n",
    "plots_names= plots_1_name+\"_\"+plots_2_name\n",
    "plot_output_folder = \"./files/plots\"\n",
    "# plots_name is the name that will be used for the plots generated during the execution of this notebook\n",
    "print(\"Plots name: \", plots_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Full trajectory\n",
    "\n",
    "We start by creating a variable that contains every path of the full (40) trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs = []\n",
    "for i in range(1, 21):\n",
    "    if i % 10 == 0:\n",
    "        conformation = 10\n",
    "    else:\n",
    "        conformation = i % 10\n",
    "\n",
    "    traj_path = (\n",
    "        \"./files/xtc_files/output.checkpoint/fs_\"\n",
    "        + str(conformation)\n",
    "        + \"_traj_\"\n",
    "        + str(i)\n",
    "        + \"/out_md/traj_comp_whole.xtc\"\n",
    "    )\n",
    "    trajs.append(traj_path)\n",
    "    # print(traj_path)\n",
    "\n",
    "    traj_path = (\n",
    "        \"./files/xtc_files/output/fs_\"\n",
    "        + str(conformation)\n",
    "        + \"_traj_\"\n",
    "        + str(i)\n",
    "        + \"/out_md/traj_comp_whole.xtc\"\n",
    "    )\n",
    "    trajs.append(traj_path)\n",
    "    # print(traj_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the trajectories as an MDtraj object. For this we use the previous variable that contains every path of the trajectories and the topological file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdtrajectories = md.load(trajs, top=top_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally load the backbone torsions of the topological file and add them into memory so we have all the trajectories with their correspondent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = coor.featurizer(top_file) \n",
    "feat.add_backbone_torsions()\n",
    "features_ref = feat.transform(mdtrajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Tica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze the conformational space, we first create its 2D representation by applying a time-lagged Independent\n",
    "Component Analysis (tICA) decomposition method to the full trajectories. We choose a time lag of 5000.\n",
    "\n",
    "To do this task we use Pyemma's libraries. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with settings(show_progress_bars=True):\n",
    "    tica_obj = coor.tica(features_ref, lag=5000, stride=stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data from our tICA object using the get_output() function, which maps all input data and returns it as an array or list of arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tica_outpu = tica_obj.get_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we concatenate the all the values of the tICA space in a single variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tica_concatenated_full = np.concatenate(tica_outpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "To discretize the full space of the tICA space we use k-means clustering.\n",
    "\n",
    "From now, we use only the first two tICA components which reflect the two slowest degrees of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust = coor.cluster_kmeans(\n",
    "    tica_concatenated_full[:,:2], k=200, stride=stride, fixed_seed=True #, metric=\"minRMSD\"\n",
    ")\n",
    "dtrajs = clust.dtrajs # Discretized trajectories\n",
    "cc_x = clust.clustercenters[:, 0] # Cluster centers of the first tICA component\n",
    "cc_y = clust.clustercenters[:, 1] # Cluster centers of the second tICA component\n",
    "dtrajs_concatenated = np.concatenate(dtrajs) # Concatenated discretized trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Trimmed trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the comparison we need to load the trajectories that have been early terminated with the use of our A4MD framework. \n",
    "\n",
    "To cut the trajectories, we leverage two essential quantities that we compute in situ as an MD simulation evolves: the largest eigenvalue of alpha-Carbon (Cùõº) distance matrices (LEV) capturing molecular states and the effective sample size (ESS) identifying fast transitions of molecular states. \n",
    "\n",
    "To start the loading process we set the source of these trajectories by using the source() function of Pyemma's library and use the same features as for the full trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdtraj_trimmed_trajectory_1 = coor.source([trimmed_trajectory_1], features=feat)\n",
    "mdtraj_trimmed_trajectory_2 = coor.source([trimmed_trajectory_2], features=feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the trajectories as MDtraj objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdtrajectories_trimmed_1 = md.load(trimmed_trajectory_1, top=top_file)\n",
    "mdtrajectories_trimmed_2 = md.load(trimmed_trajectory_2, top=top_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we map all input data as a list of arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_trajs_1= mdtraj_trimmed_trajectory_1.get_output()\n",
    "loaded_trajs_2 = mdtraj_trimmed_trajectory_2.get_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating tICA for trimmed trajectories using the full tICA object\n",
    "\n",
    "Since we have the tICA object of the full trajectories, we map the trimmed trajectories into the same space, to that end we use the transform() function of Pyemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tica_transformed_trim_1 = tica_obj.transform(loaded_trajs_1)\n",
    "tica_transformed_trim_2 = tica_obj.transform(loaded_trajs_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did with the full trajectories, we concatenate the trimmed trajectories in a single variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tica_concatenated_trim_1 = np.concatenate(tica_transformed_trim_1)\n",
    "tica_concatenated_trim_2 = np.concatenate(tica_transformed_trim_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "Assigning trimmed data to the cluster centers of the full trajectory suing the euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrajs_trimmed_1 = coor.assign_to_centers(tica_concatenated_trim_1[:,:2], clust.clustercenters, metric='euclidean',return_dtrajs=True)\n",
    "dtrajs_trimmed_2 = coor.assign_to_centers(tica_concatenated_trim_2[:,:2], clust.clustercenters, metric='euclidean',return_dtrajs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Markov Model\n",
    "\n",
    "We build a Markov State Model (MSM) to describe the dynamics and kinetics of the Fs peptide folding. \n",
    "\n",
    "We create three MSM, one for the full trajectories and two for the trimmed trajectories either using LEV or ESS.\n",
    "\n",
    "We select a time lag of 100 and use the VAMP method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = pyemma.msm.estimate_markov_model(dtrajs, lag=100, score_method=\"VAMP1\")\n",
    "MT_1 = pyemma.msm.estimate_markov_model(dtrajs_trimmed_1, lag=100, score_method=\"VAMP1\")\n",
    "MT_2 = pyemma.msm.estimate_markov_model(dtrajs_trimmed_2, lag=100, score_method=\"VAMP1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing PCCA+\n",
    "\n",
    "We perform another clustering method. Now we use the Perron-Cluster Clustering Analysis (PCCA) to do a fuzzy clustering.\n",
    "\n",
    "Here we use the number of states defined at the beggining. The number of states were defined in our previous work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "M.pcca(nstates)\n",
    "MT_1.pcca(nstates)\n",
    "MT_2.pcca(nstates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We map the cluster assignments of the trimmed data to the metastable states and then get the metastable states.\n",
    "\n",
    "During this task we use the same assignments of the full model because we want to map the trimmed points in the same clusters identified by the PCCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metastable_traj = M.metastable_assignments[dtrajs_concatenated]\n",
    "metastable_assignments_trimmed_1 = M.metastable_assignments[dtrajs_trimmed_1]\n",
    "metastable_assignments_trimmed_2 = M.metastable_assignments[dtrajs_trimmed_2]\n",
    "\n",
    "pcca_sets = M.metastable_sets\n",
    "pcca_setsT = MT_1.metastable_sets\n",
    "pcca_setsT_2 = MT_2.metastable_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting state maps\n",
    "We use one of the functions from Pyemma to visualize the state maps that we got from doing the PCCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3) = plt.subplots(ncols=3, sharey=True, sharex=True, figsize=(18, 10))\n",
    "cols = [\"orange\", \"yellow\", \"limegreen\", \"cyan\", \"magenta\", \"royalblue\"]\n",
    "cols_2 = [\"magenta\", \"royalblue\", \"cyan\", \"limegreen\", \"yellow\", \"orange\"]\n",
    "cmap = mpl.colors.ListedColormap(cols)\n",
    "pyemma.plots.plot_state_map(\n",
    "    tica_concatenated_full[:, 0],\n",
    "    tica_concatenated_full[:, 1],\n",
    "    metastable_traj,\n",
    "    cbar_label=\"Full\",\n",
    "    cbar=True,\n",
    "    cbar_orientation=\"horizontal\",\n",
    "    cmap=cmap,\n",
    "    ncontours=200,\n",
    "    nbins=200,\n",
    "    ax=ax1,\n",
    ")\n",
    "ax1.set_xlabel(\"TIC 1\")\n",
    "ax1.set_ylabel(\"TIC 2\")\n",
    "pyemma.plots.plot_state_map(\n",
    "    tica_concatenated_trim_1[:, 0],\n",
    "    tica_concatenated_trim_1[:, 1],\n",
    "    np.asarray(metastable_assignments_trimmed_1).reshape(-1),\n",
    "    cbar_label=\"LEV\",\n",
    "    cbar=True,\n",
    "    cbar_orientation=\"horizontal\",\n",
    "    cmap=cmap,\n",
    "    ncontours=300,\n",
    "    nbins=200,\n",
    "    ax=ax2,\n",
    ")\n",
    "ax2.set_xlabel(\"TIC 1\")\n",
    "ax2.set_ylabel(\"TIC 2\")\n",
    "pyemma.plots.plot_state_map(\n",
    "    tica_concatenated_trim_2[:, 0],\n",
    "    tica_concatenated_trim_2[:, 1],\n",
    "    np.asarray(metastable_assignments_trimmed_2).reshape(-1),\n",
    "    cbar_label=\"ESS\",\n",
    "    cbar=True,\n",
    "    cbar_orientation=\"horizontal\",\n",
    "    cmap=cmap,\n",
    "    ncontours=300,\n",
    "    nbins=200,\n",
    "    ax=ax3,\n",
    ")\n",
    "ax3.set_xlabel(\"TIC 1\")\n",
    "ax3.set_ylabel(\"TIC 2\")\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "ax3.grid()\n",
    "plt.tight_layout()\n",
    "if SAVE_PLOTS:\n",
    "    plt.savefig(os.path.join(plot_output_folder, plots_names + \"_state_map.png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Energy\n",
    "\n",
    "Now we calculate the Free Energy landscape for the three models we have ( on for full and two for the early terminated trajectories). We do this calculation using MSM stationary distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationary Distribution - Energy\n",
    "\n",
    "\n",
    "This cell calculates the free energies for three different distributions: full, trimmed, and trimmed ess.\n",
    "It uses the Boltzmann equation based on stationary distributions and total distributions of each distribution to calculate the probabilities (pi).\n",
    "The free energies are then calculated as the negative logarithm of the probabilities.\n",
    "The minimum value of the free energies for the full distribution is subtracted from all the free energies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Full\n",
    "stationary_distribution = M.stationary_distribution\n",
    "total_distribution = float(stationary_distribution.sum())\n",
    "pi = stationary_distribution / total_distribution\n",
    "free_energies = -np.log(pi)\n",
    "min_full = np.min(free_energies)\n",
    "free_energies -= np.min(free_energies)\n",
    "free_energies = np.round(free_energies, 2)\n",
    "\n",
    "# LEV\n",
    "stationary_distributionT_1 = MT_1.stationary_distribution\n",
    "total_distributionT_1 = float(stationary_distributionT_1.sum())\n",
    "piT = stationary_distributionT_1 / total_distributionT_1\n",
    "free_energiesT_1 = -np.log(piT)\n",
    "free_energiesT_1 -= min_full\n",
    "free_energiesT_1 -= np.min(free_energiesT_1)\n",
    "free_energiesT_1 = np.round(free_energiesT_1, 2)\n",
    "\n",
    "# ESS\n",
    "stationary_distributionT_2 = MT_2.stationary_distribution\n",
    "total_distributionT_2 = float(stationary_distributionT_2.sum())\n",
    "piT_2 = stationary_distributionT_2 / total_distributionT_2\n",
    "free_energiesT_2 = -np.log(piT_2)\n",
    "free_energiesT_2 -= min_full\n",
    "free_energiesT_2 -= np.min(free_energiesT_2)\n",
    "free_energiesT_2 = np.round(free_energiesT_2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Frames closest to minimum free energy\n",
    "To find the most representatives structures per state, we find the closest frames to the minimum values per state.\n",
    "\n",
    "We find the 10 closest frames, so we can compare them to verify whether their structure is similar or not.\n",
    "\n",
    "We do this for every model and Free Energy calculation \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: change to dataframe structure or create a class with these attributes so we only pass the object\n",
    "print(\"Stationary\")\n",
    "(\n",
    "    frames_closest_to_minimum_energy_coor_stationary,\n",
    "    frames_closest_to_minimum_energy_coor_T_1_stationary,\n",
    "    frames_closest_to_minimum_energy_coor_T_2_stationary,\n",
    "    frames_closest_to_minimum_energy_stationary,\n",
    "    frames_closest_to_minimum_energyT_1_stationary,\n",
    "    frames_closest_to_minimum_energyT_2_stationary,\n",
    "    frames_10_closest_to_minimum_energy_stationary,\n",
    "    frames_10_closest_to_minimum_energyT_1_stationary,\n",
    "    frames_10_closest_to_minimum_energyT_2_stationary,\n",
    "    minimum_energy_stationary,\n",
    "    minimum_energyT_stationary,\n",
    "    minimum_energyT_2_stationary,\n",
    ") = jpccck.find_frames_closest_to_minimum_energy(\n",
    "    FES=free_energies,\n",
    "    FES_T=free_energiesT_1,\n",
    "    FES_T_2=free_energiesT_2,\n",
    "    M=M,\n",
    "    MT=MT_1,\n",
    "    MT_2=MT_2,\n",
    "    clust=clust,\n",
    "    tica_concatenated_full=tica_concatenated_full,\n",
    "    tica_concatenated_trim_1=tica_concatenated_trim_1,\n",
    "    tica_concatenated_trim_2=tica_concatenated_trim_2,\n",
    "    nstates=nstates,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy Ranking - Stationary Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_coor_full = list(np.round(frames_closest_to_minimum_energy_coor_stationary, 1))\n",
    "min_coor_1 = list(np.round(frames_closest_to_minimum_energy_coor_T_1_stationary, 1))\n",
    "min_coor_2 = list(np.round(frames_closest_to_minimum_energy_coor_T_2_stationary, 1))\n",
    "\n",
    "data = {\n",
    "    'State': range(0, len(minimum_energy_stationary)),\n",
    "    f'Coordinates {full_title}': min_coor_full,\n",
    "    f'Minimum Energy ({full_title})': minimum_energy_stationary,\n",
    "    f'Coordinates {trimmed_1_title}': min_coor_1,\n",
    "    f'Minimum Energy ({trimmed_1_title})': minimum_energyT_stationary,\n",
    "    f'Coordinates {trimmed_2_title}': min_coor_2,\n",
    "    f'Minimum Energy ({trimmed_2_title})': minimum_energyT_2_stationary,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df_sorted = df.sort_values(by=f'Minimum Energy ({full_title})')\n",
    "display(df_sorted)\n",
    "if SAVE_PLOTS:\n",
    "    # save table as image\n",
    "    dfi.export(df_sorted, os.path.join(plot_output_folder, plots_names + \"_minimum_energy_table.png\"),table_conversion = 'matplotlib' )\n",
    "    # save the table as csv for further analysis\n",
    "    df.to_csv(f'{plot_output_folder}/{plots_names}_minimum_energy_table.csv', mode='a', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving closest frames to disk as pdb files\n",
    "\n",
    "We save the closest frames to disk to visualize them using VMD and to do the RMSD calculation later.\n",
    "\n",
    "The folder that contains the frames will have the 10 closest frames but also the closest one. We name this folder with the datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: change to dataframe structure or create a class with these attributes so we only pass the object\n",
    "if SAVE_FRAMES:\n",
    "    folder = datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    folder_path = f\"{frames_closest_folder}{folder}\"\n",
    "    os.mkdir(folder_path)\n",
    "    folder_path_10 = f\"{folder_path}/frames_10\"\n",
    "    os.mkdir(folder_path_10)\n",
    "\n",
    "    frames_10_total_stationary, frames_10_files_stationary = jpccck.save_10_frames(\n",
    "        folder_path_10,\n",
    "        \"stationary\",\n",
    "        frames_10_closest_to_minimum_energy_stationary,\n",
    "        mdtrajectories,\n",
    "        \"full\",\n",
    "    )\n",
    "\n",
    "    frames_10T_1_total_stationary, frames_10_filesT_1_stationary = (\n",
    "        jpccck.save_10_frames(\n",
    "            folder_path_10,\n",
    "            \"stationary\",\n",
    "            frames_10_closest_to_minimum_energyT_1_stationary,\n",
    "            mdtrajectories_trimmed_1,\n",
    "            \"trim_1\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    frames_10T_2_total_stationary, frames_10_filesT_2_stationary = (\n",
    "        jpccck.save_10_frames(\n",
    "            folder_path_10,\n",
    "            \"stationary\",\n",
    "            frames_10_closest_to_minimum_energyT_2_stationary,\n",
    "            mdtrajectories_trimmed_2,\n",
    "            \"trim_2\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    frames_minimum_stationary, frames_minimum_files_stationary = jpccck.save_frames(\n",
    "        folder_path,\n",
    "        \"stationary\",\n",
    "        frames_closest_to_minimum_energy_stationary,\n",
    "        mdtrajectories,\n",
    "        \"full\",\n",
    "    )\n",
    "\n",
    "    frames_minimumT_1_stationary, frames_minimum_filesT_1_stationary = (\n",
    "        jpccck.save_frames(\n",
    "            folder_path,\n",
    "            \"stationary\",\n",
    "            frames_closest_to_minimum_energyT_1_stationary,\n",
    "            mdtrajectories_trimmed_1,\n",
    "            \"trim_1\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    frames_minimumT_2_stationary, frames_minimum_filesT_2_stationary = (\n",
    "        jpccck.save_frames(\n",
    "            folder_path,\n",
    "            \"stationary\",\n",
    "            frames_closest_to_minimum_energyT_2_stationary,\n",
    "            mdtrajectories_trimmed_2,\n",
    "            \"trim_2\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Free energy landscapes and minimum per state\n",
    "We use the tricontour plot to visualize the Free Energy landscape for all the three methods we used. In this plot we also present the cluster centers that we got from the kmeans clustering, in every color we also see the different states and as a white star we see the minimum Free Energy points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpccck.plot_free_energy(\n",
    "    cc_x=cc_x,\n",
    "    cc_y=cc_y,\n",
    "    free_energy_per_cluster=free_energies,\n",
    "    free_energy_per_clusterT=free_energiesT_1,\n",
    "    free_energy_per_clusterT_2=free_energiesT_2,\n",
    "    dist_cmap=dist_cmap,\n",
    "    nstates=nstates,\n",
    "    pcca_sets=pcca_sets,\n",
    "    cols=cols,\n",
    "    size=35,\n",
    "    frames_closest_to_minimum_energy_coor=frames_closest_to_minimum_energy_coor_stationary,\n",
    "    frames_closest_to_minimum_energy_coorT=frames_closest_to_minimum_energy_coor_T_1_stationary,\n",
    "    frames_closest_to_minimum_energy_coorT_2=frames_closest_to_minimum_energy_coor_T_2_stationary,\n",
    "    no_points=False,\n",
    "    full_title=full_title,\n",
    "    trimmed_1_title=trimmed_1_title,\n",
    "    trimmed_2_title=trimmed_2_title,\n",
    ")\n",
    "if SAVE_PLOTS:\n",
    "    plt.savefig(os.path.join(plot_output_folder, plots_names + \"_energy.png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating RMSD average within same states (10 Closest Frames)\n",
    "We take the 10 closest frames and calculate the RMSD average among them. We are using two methods to do this. The mdtraj method aligns all the frames and then does the comparison. The Compute method does the comparison without aligning the frames. For both methods we use the closest frame to the minium Free Energy point as reference. We do this only for Pyemma's Free Energy due to this one represented better the landscape comparing it to the full simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_average_rmsd = {'State': range(0, len(minimum_energy_stationary))}\n",
    "data_average_rmsd[\"full_mdtraj\"] = jpccck.calculate_average_rmsd(frames_10_total_stationary, frames_10_files_stationary, 'mdtraj', nstates, selection)\n",
    "\n",
    "data_average_rmsd[\"trimmed_1_mdtraj\"] = jpccck.calculate_average_rmsd(frames_10T_1_total_stationary, frames_10_filesT_1_stationary, 'mdtraj', nstates, selection)\n",
    "\n",
    "data_average_rmsd[\"trimmed_2_mdtraj\"] = jpccck.calculate_average_rmsd(frames_10T_2_total_stationary, frames_10_filesT_2_stationary, 'mdtraj', nstates, selection)\n",
    "df_average_rmsd = pd.DataFrame(data_average_rmsd)\n",
    "display(df_average_rmsd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of the Free Energy comparison between Full trajectories and Trimmed\n",
    "\n",
    "These plots show the comparison of the free energy per microstate in the different trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# First plot: Free Energies and Free EnergiesT\n",
    "df1 = pd.DataFrame({full_title: free_energies, trimmed_1_title: free_energiesT_1})\n",
    "pl1 = df1.plot(figsize=(12, 6))\n",
    "plt.xlabel('Microstate', fontsize=14)\n",
    "plt.ylabel('Free Energy', fontsize=14)\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)  # Increase the font size of the ticks on both axes\n",
    "plt.title('FES', fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "plt.savefig(os.path.join(plot_output_folder, plots_names + \"_free_energy_line_comparison_1.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Second plot: Free Energies and Free EnergiesT Ess\n",
    "df2 = pd.DataFrame({full_title: free_energies, trimmed_2_title: free_energiesT_2})\n",
    "pl2 = df2.plot(figsize=(12, 6))\n",
    "plt.xlabel('Microstate', fontsize=14)\n",
    "plt.ylabel('Free Energy', fontsize=14)\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)  # Increase the font size of the ticks on both axes\n",
    "plt.title('FES', fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "if SAVE_PLOTS:\n",
    "    plt.savefig(os.path.join(plot_output_folder, plots_names + \"_free_energyT_2_line_comparison_2.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM\n",
    "We do the estimation of the Hidden Markov Model that can represent better the transitions among states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_full = pyemma.msm.estimate_hidden_markov_model(dtrajs, 6, lag=100)\n",
    "hmm_1 = pyemma.msm.estimate_hidden_markov_model(dtrajs_trimmed_1, 6, lag=100)\n",
    "hmm_2 = pyemma.msm.estimate_hidden_markov_model(dtrajs_trimmed_2, 6, lag=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the state maps for the HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"orange\", \"yellow\", \"limegreen\", \"cyan\", \"royalblue\", \"magenta\"]\n",
    "cmap = mpl.colors.ListedColormap(cols)\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(ncols=3, figsize=(15, 10), sharex=True, sharey=True)\n",
    "\n",
    "\n",
    "pyemma.plots.plot_state_map(\n",
    "    *tica_concatenated_full[:, :2].T,\n",
    "    hmm_full.metastable_assignments[dtrajs_concatenated],\n",
    "    ax=ax1,\n",
    "    cmap='viridis',\n",
    "    nbins=300,\n",
    "    cbar=True,\n",
    "    cbar_orientation=\"horizontal\",\n",
    ")\n",
    "ax1.set_xlabel(\"TIC 1\")\n",
    "ax1.set_ylabel(\"TIC 2\")\n",
    "pyemma.plots.plot_state_map(\n",
    "    *tica_concatenated_trim_1[:, :2].T,\n",
    "    np.asarray(hmm_full.metastable_assignments[dtrajs_trimmed_1]).reshape(-1),\n",
    "    ax=ax2,\n",
    "    cmap='viridis',\n",
    "    nbins=300,\n",
    "    cbar=True,\n",
    "    cbar_orientation=\"horizontal\",\n",
    ")\n",
    "ax2.set_xlabel(\"TIC 1\")\n",
    "ax2.set_ylabel(\"TIC 2\")\n",
    "pyemma.plots.plot_state_map(\n",
    "    *tica_concatenated_trim_2[:, :2].T,\n",
    "    np.asarray(hmm_full.metastable_assignments[dtrajs_trimmed_2]).reshape(-1),\n",
    "    ax=ax3,\n",
    "    cmap='viridis',\n",
    "    nbins=300,\n",
    "    cbar=True,\n",
    "    cbar_orientation=\"horizontal\",\n",
    ")\n",
    "ax3.set_xlabel(\"TIC 1\")\n",
    "ax3.set_ylabel(\"TIC 2\")\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "ax3.grid()\n",
    "plt.tight_layout()\n",
    "if SAVE_PLOTS:\n",
    "    plt.savefig(os.path.join(plot_output_folder, plots_names + \"_hmm.png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Free Energy - HMM - Stationary\n",
    "We calculate the Free Energy of the HMM. This calculation uses same Boltzmann equation we previously used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full\n",
    "stationary_distribution = hmm_full.stationary_distribution\n",
    "total_distribution = float(stationary_distribution.sum())\n",
    "pi = stationary_distribution / total_distribution\n",
    "hmm_full_free_energies = -np.log(pi)\n",
    "min_full = np.min(hmm_full_free_energies)\n",
    "hmm_full_free_energies -= np.min(hmm_full_free_energies)\n",
    "\n",
    "# trimmed - 1\n",
    "stationary_distributionT = hmm_1.stationary_distribution\n",
    "total_distributionT = float(stationary_distributionT.sum())\n",
    "piT = stationary_distributionT / total_distributionT\n",
    "hmm_1_free_energiesT = -np.log(piT)\n",
    "hmm_1_free_energiesT -= min_full\n",
    "hmm_1_free_energiesT -= np.min(hmm_1_free_energiesT)\n",
    "\n",
    "# trimmed - 2\n",
    "stationary_distributionT_2 = hmm_2.stationary_distribution\n",
    "total_distributionT_2 = float(stationary_distributionT_2.sum())\n",
    "piT_2 = stationary_distributionT_2 / total_distributionT_2\n",
    "hmm_2_free_energiesT_2 = -np.log(piT_2)\n",
    "hmm_2_free_energiesT_2 -= min_full\n",
    "hmm_2_free_energiesT_2 -= np.min(hmm_2_free_energiesT_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[f'hmm_{full_title}'] = hmm_full_free_energies\n",
    "data[f'hmm_{trimmed_1_title}'] = hmm_1_free_energiesT\n",
    "data[f'hmm_{trimmed_2_title}'] = hmm_2_free_energiesT_2\n",
    "df = pd.DataFrame(data)\n",
    "# df_sorted = df.sort_values(by='Minimum Energy (PyEmma)')\n",
    "display(df)\n",
    "if SAVE_PLOTS:\n",
    "    # save table as image\n",
    "    dfi.export(df, os.path.join(plot_output_folder, plots_names + \"_hmm_free_energy_table.png\"),table_conversion = 'matplotlib' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
